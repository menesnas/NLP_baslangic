{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8d7991b-7c72-4085-95c4-c982b8e7760b",
   "metadata": {},
   "source": [
    "### NLP Ã¶n iÅŸleme pratiÄŸi\n",
    "    KullanÄ±lan teknikler :\n",
    "- postag (sÄ±fat/zamir gibi kelime tÃ¼rlerini bulma)\n",
    "- stopwords (tek baÅŸÄ±na anlamsÄ±z kelimeleri kaldÄ±rmak iÃ§in)\n",
    "- counter (kelime sÄ±klÄ±ÄŸÄ± iÃ§in)\n",
    "- Lemmatization / Stemming (KÃ¶k bulmak iÃ§in)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ab44ba-9e50-49d6-90a5-10c0feaf2e7f",
   "metadata": {},
   "source": [
    "## Twitter iklim krizi verileri ile nlp Ã¶n iÅŸleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ff59916a-4a9f-462d-9af3-4d00ce60073a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sbn\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf11816e-e639-44f2-85b4-a8cfc387e0e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tarih</th>\n",
       "      <th>id</th>\n",
       "      <th>icerik</th>\n",
       "      <th>ad</th>\n",
       "      <th>konum</th>\n",
       "      <th>begeni</th>\n",
       "      <th>rt</th>\n",
       "      <th>takipci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-31 22:59:36</td>\n",
       "      <td>1609323416154243072</td>\n",
       "      <td>@Fapej_in_Tufegi YAAAAAAAAAAAAAAAAAAAAAA \\n\\nN...</td>\n",
       "      <td>bazenzorgeliyo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-31 21:12:22</td>\n",
       "      <td>1609296428232510976</td>\n",
       "      <td>@wolfintoaction Kurak geÃ§en bir yÄ±l var ortada...</td>\n",
       "      <td>yesiturk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-31 17:09:59</td>\n",
       "      <td>1609235429089328896</td>\n",
       "      <td>2021 ; DoÄŸanÄ±n bize verdiklerinin yanÄ±nda bizi...</td>\n",
       "      <td>guvenada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-31 17:01:48</td>\n",
       "      <td>1609233370898202880</td>\n",
       "      <td>Erzurumâ€™un yeni yÄ±la karsÄ±z girecek olmasÄ±â€¦ ko...</td>\n",
       "      <td>kizginbirkiz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-31 15:08:54</td>\n",
       "      <td>1609204959177854976</td>\n",
       "      <td>[Ankara'nÄ±n iklim gÃ¼ndemi-9] HDP: Ä°klim krizi ...</td>\n",
       "      <td>yesillersol_izm</td>\n",
       "      <td>izmir</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                tarih                   id  \\\n",
       "0 2022-12-31 22:59:36  1609323416154243072   \n",
       "1 2022-12-31 21:12:22  1609296428232510976   \n",
       "2 2022-12-31 17:09:59  1609235429089328896   \n",
       "3 2022-12-31 17:01:48  1609233370898202880   \n",
       "4 2022-12-31 15:08:54  1609204959177854976   \n",
       "\n",
       "                                              icerik               ad  konum  \\\n",
       "0  @Fapej_in_Tufegi YAAAAAAAAAAAAAAAAAAAAAA \\n\\nN...   bazenzorgeliyo    NaN   \n",
       "1  @wolfintoaction Kurak geÃ§en bir yÄ±l var ortada...         yesiturk    NaN   \n",
       "2  2021 ; DoÄŸanÄ±n bize verdiklerinin yanÄ±nda bizi...         guvenada    NaN   \n",
       "3  Erzurumâ€™un yeni yÄ±la karsÄ±z girecek olmasÄ±â€¦ ko...     kizginbirkiz    NaN   \n",
       "4  [Ankara'nÄ±n iklim gÃ¼ndemi-9] HDP: Ä°klim krizi ...  yesillersol_izm  izmir   \n",
       "\n",
       "   begeni  rt  takipci  \n",
       "0       1   0      145  \n",
       "1       1   0      376  \n",
       "2       1   0     3263  \n",
       "3       7   0       30  \n",
       "4       1   1     1854  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"iklim_krizi.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49dd70cf-e2d4-4488-99f7-4fd4e6d91432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tarih          0\n",
       "id             0\n",
       "icerik         0\n",
       "ad             0\n",
       "konum      13342\n",
       "begeni         0\n",
       "rt             0\n",
       "takipci        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09591bd7-ef17-4e8f-bd74-c29afe7ca360",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tarih</th>\n",
       "      <th>id</th>\n",
       "      <th>icerik</th>\n",
       "      <th>ad</th>\n",
       "      <th>begeni</th>\n",
       "      <th>rt</th>\n",
       "      <th>takipci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-31 22:59:36</td>\n",
       "      <td>1609323416154243072</td>\n",
       "      <td>@Fapej_in_Tufegi YAAAAAAAAAAAAAAAAAAAAAA \\n\\nN...</td>\n",
       "      <td>bazenzorgeliyo</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-31 21:12:22</td>\n",
       "      <td>1609296428232510976</td>\n",
       "      <td>@wolfintoaction Kurak geÃ§en bir yÄ±l var ortada...</td>\n",
       "      <td>yesiturk</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-31 17:09:59</td>\n",
       "      <td>1609235429089328896</td>\n",
       "      <td>2021 ; DoÄŸanÄ±n bize verdiklerinin yanÄ±nda bizi...</td>\n",
       "      <td>guvenada</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-31 17:01:48</td>\n",
       "      <td>1609233370898202880</td>\n",
       "      <td>Erzurumâ€™un yeni yÄ±la karsÄ±z girecek olmasÄ±â€¦ ko...</td>\n",
       "      <td>kizginbirkiz</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-31 15:08:54</td>\n",
       "      <td>1609204959177854976</td>\n",
       "      <td>[Ankara'nÄ±n iklim gÃ¼ndemi-9] HDP: Ä°klim krizi ...</td>\n",
       "      <td>yesillersol_izm</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                tarih                   id  \\\n",
       "0 2022-12-31 22:59:36  1609323416154243072   \n",
       "1 2022-12-31 21:12:22  1609296428232510976   \n",
       "2 2022-12-31 17:09:59  1609235429089328896   \n",
       "3 2022-12-31 17:01:48  1609233370898202880   \n",
       "4 2022-12-31 15:08:54  1609204959177854976   \n",
       "\n",
       "                                              icerik               ad  begeni  \\\n",
       "0  @Fapej_in_Tufegi YAAAAAAAAAAAAAAAAAAAAAA \\n\\nN...   bazenzorgeliyo       1   \n",
       "1  @wolfintoaction Kurak geÃ§en bir yÄ±l var ortada...         yesiturk       1   \n",
       "2  2021 ; DoÄŸanÄ±n bize verdiklerinin yanÄ±nda bizi...         guvenada       1   \n",
       "3  Erzurumâ€™un yeni yÄ±la karsÄ±z girecek olmasÄ±â€¦ ko...     kizginbirkiz       7   \n",
       "4  [Ankara'nÄ±n iklim gÃ¼ndemi-9] HDP: Ä°klim krizi ...  yesillersol_izm       1   \n",
       "\n",
       "   rt  takipci  \n",
       "0   0      145  \n",
       "1   0      376  \n",
       "2   0     3263  \n",
       "3   0       30  \n",
       "4   1     1854  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=\"konum\",axis=1,inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bcf45a6-17f3-4cdb-a65a-9a00e2751701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           begeni        rt   takipci\n",
      "begeni   1.000000  0.696226  0.272222\n",
      "rt       0.696226  1.000000  0.180406\n",
      "takipci  0.272222  0.180406  1.000000\n"
     ]
    }
   ],
   "source": [
    "correlation_matrix = df[['begeni','rt', 'takipci']].corr()\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b844c5-ae46-4839-af8f-78ee789f34c7",
   "metadata": {},
   "source": [
    "### NLP kÃ¼tÃ¼phaneleri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5599b7f1-b223-4254-ac5f-be3de6c4515e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from collections import Counter\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # UyarÄ± mesajlarÄ±nÄ± gizleyelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06b44478-2be5-4a1e-94a2-a875a2e2151a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\menes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\menes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\menes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\menes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "\n",
    "# POS tag'leri WordNet formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in fonksiyon\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN  # VarsayÄ±lan olarak isim alÄ±r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03fc5b6-5eab-4cb3-a001-ebdd360dc901",
   "metadata": {},
   "outputs": [],
   "source": [
    "metin = df[\"icerik\"].tolist()\n",
    "metin[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd91bf6-eb91-41c2-8c45-064c56fd1ee4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metin_list = \" \".join(metin)\n",
    "kelimeler = nltk.word_tokenize(metin_list)\n",
    "counter = Counter(kelimeler)\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0970b1e3-2cf3-4a2d-8fd2-8e422b2acca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens :  ['@', 'Fapej_in_Tufegi', 'YAAAAAAAAAAAAAAAAAAAAAA', 'Neyse', 'komÃ¼nist', 'olmak', 'da', 'gÃ¼zel', 'ÅŸey', 'eÅŸitlik']\n"
     ]
    }
   ],
   "source": [
    "kelimeler = nltk.word_tokenize(metin_list)\n",
    "print(\"Tokens : \",kelimeler[:10]) ## Jupyter Notebook sunucusu Ã§ok bÃ¼yÃ¼k verilerde Ã§Ä±ktÄ±yÄ± vermiyordu. Bu yÃ¼zden ilk 10 veri gÃ¶sterildi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68095170-88f2-45be-b676-90d48dccbc9b",
   "metadata": {},
   "source": [
    "### KÃ¶klendirme \n",
    "- Stemming veya lemmatization kullanÄ±lÄ±r.\n",
    "- Stemming direkt kÃ¶ke odaklanÄ±r\n",
    "- Lemmatization anlamlÄ± kÃ¶klere odaklanÄ±r (better olan kelimenin kÃ¶kÃ¼ good olmasÄ± gibi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c66bbae4-db06-4a38-9a60-46b0284e33a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kok sonrasi :  ['@', 'Fapej_in_Tufegi', 'YAAAAAAAAAAAAAAAAAAAAAA', 'Neyse', 'komÃ¼nist', 'olmak', 'da', 'gÃ¼zel', 'ÅŸey', 'eÅŸitlik', 'falan', 'savunuyorsun', 'iklim', 'krizi', 'olmuyor', '@', 'wolfintoaction', 'Kurak', 'geÃ§en', 'bir', 'yÄ±l', 'var', 'ortada', 'kuraklÄ±k', 'iyice', 'baÅŸ', 'gÃ¶sterip', 'gÄ±da', 've', 'iklim', 'krizi', 'olursa', 'beton', 've', 'diÄŸer', 'menkul', 'yahut', 'gayrimenkullerin', 'yenilip', 'iÃ§ilmediÄŸi', 'iÃ§in', 'gÄ±dadan', 'daha', 'fazla', 'Ã¶nem', 'teÅŸkil', 'etmeyecek', 'gÃ¼n', 'gelir', 'Ã§erez', 'parasÄ±', 'da', 'olur', 'makyajlÄ±', 'beton', 'evler', '2021', ';', 'DoÄŸanÄ±n', 'bize', 'verdiklerinin', 'yanÄ±nda', 'bizim', 'onu', 'nasÄ±l', 'hunharca', 'yok', 'ettiÄŸimizi', 'hatÄ±rlattÄ±', '..', 'AdÄ±na', 'ister', 'iklim', 'krizi', 'deyin', ',', 'ister', 'baÅŸka', 'birÅŸey', '..', 'https', ':', '//t.co/2rtifFHMfY', 'Erzurum', 'â€™', 'un', 'yeni', 'yÄ±la', 'karsÄ±z', 'girecek', 'olmasÄ±â€¦', 'korkunÃ§â€¦', 'kÃ¼resel', 'Ä±sÄ±nmaâ€¦', 'yok', 'olan', 'mevsimlerâ€¦', 'iklim', 'kriziâ€¦', 'her', 'ÅŸeyin', 'deÄŸiÅŸmesiâ€¦', 'normal', 'hiÃ§bir', 'ÅŸey', 'kalmamasÄ±â€¦', '[', \"Ankara'nÄ±n\", 'iklim', 'gÃ¼ndemi-9', ']', 'HDP', ':', 'Ä°klim', 'krizi', 'yeni', 'kazanÃ§', 'kapÄ±sÄ±', 'olamaz', '-', 'YeÅŸil', 'Gazete', 'https', ':', '//t.co/0NGWYjSFAr', 'iklim', 'krizi', 'yÃ¼zÃ¼nden', ',', 'yÄ±l', 'baÅŸÄ±', 'bu', 'sene', 'yaza', 'denk', 'gelmiÅŸ', 'gibi', '#', 'Noel', \"2023'te\", 'dÃ¼nyayÄ±', 'Rusya-Ukrayna', 'krizinin', 'etkileri', 've', 'enerji', 'krizi', 'riski', 'bekliyor', ':', \"2023'te\", 'dÃ¼nyayÄ±', 'Rusya-Ukrayna', 'savaÅŸÄ±nÄ±n', 'devam', 'etmesi', ',', 'petrol', 'fiyatlarÄ±nÄ±n', 'artmasÄ±yla', 'meydana', 'gelen', 'enerji', 'krizi', ',', 'gÄ±da', 'gÃ¼vensizliÄŸi', ',', 'ekonomik', 'kriz', 've', 'iklim', 'deÄŸiÅŸikliÄŸi', 'gibiâ€¦', 'https', ':', '//t.co/rRnOcexgYS', '@', 'huseyinkanturk', 'gÄ±da', 've', 'ilaÃ§', 'stoklamak', 'mÄ±', 'yoksa', 'bunlarÄ±n', 'hisselerini', 'almak', 'mÄ±', 'daha', 'yararlÄ±', 'olur', 'ğŸ˜‚ğŸ˜‚', 'birde', 'iklim', 'krizi', 'de', 'olacakmÄ±ÅŸ', '.', 'Sanat']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "kok sonrasi :  ['@', 'fapej_in_tufegi', 'yaaaaaaaaaaaaaaaaaaaaaa', 'neys', 'komÃ¼nist', 'olmak', 'da', 'gÃ¼zel', 'ÅŸey', 'eÅŸitlik', 'falan', 'savunuyorsun', 'iklim', 'krizi', 'olmuyor', '@', 'wolfintoact', 'kurak', 'geÃ§en', 'bir', 'yÄ±l', 'var', 'ortada', 'kuraklÄ±k', 'iyic', 'baÅŸ', 'gÃ¶sterip', 'gÄ±da', 've', 'iklim', 'krizi', 'olursa', 'beton', 've', 'diÄŸer', 'menkul', 'yahut', 'gayrimenkullerin', 'yenilip', 'iÃ§ilmediÄŸi', 'iÃ§in', 'gÄ±dadan', 'daha', 'fazla', 'Ã¶nem', 'teÅŸkil', 'etmeyecek', 'gÃ¼n', 'gelir', 'Ã§erez', 'parasÄ±', 'da', 'olur', 'makyajlÄ±', 'beton', 'evler', '2021', ';', 'doÄŸanÄ±n', 'bize', 'verdiklerinin', 'yanÄ±nda', 'bizim', 'onu', 'nasÄ±l', 'hunharca', 'yok', 'ettiÄŸimizi', 'hatÄ±rlattÄ±', '..', 'adÄ±na', 'ister', 'iklim', 'krizi', 'deyin', ',', 'ister', 'baÅŸka', 'birÅŸey', '..', 'http', ':', '//t.co/2rtiffhmfi', 'erzurum', 'â€™', 'un', 'yeni', 'yÄ±la', 'karsÄ±z', 'girecek', 'olmasÄ±â€¦', 'korkunÃ§â€¦', 'kÃ¼resel', 'Ä±sÄ±nmaâ€¦', 'yok', 'olan', 'mevsimlerâ€¦', 'iklim', 'kriziâ€¦', 'her', 'ÅŸeyin', 'deÄŸiÅŸmesiâ€¦', 'normal', 'hiÃ§bir', 'ÅŸey', 'kalmamasÄ±â€¦', '[', \"ankara'nÄ±n\", 'iklim', 'gÃ¼ndemi-9', ']', 'hdp', ':', 'iÌ‡klim', 'krizi', 'yeni', 'kazanÃ§', 'kapÄ±sÄ±', 'olamaz', '-', 'yeÅŸil', 'gazet', 'http', ':', '//t.co/0ngwyjsfar', 'iklim', 'krizi', 'yÃ¼zÃ¼nden', ',', 'yÄ±l', 'baÅŸÄ±', 'bu', 'sene', 'yaza', 'denk', 'gelmiÅŸ', 'gibi', '#', 'noel', \"2023'te\", 'dÃ¼nyayÄ±', 'rusya-ukrayna', 'krizinin', 'etkileri', 've', 'enerji', 'krizi', 'riski', 'bekliyor', ':', \"2023'te\", 'dÃ¼nyayÄ±', 'rusya-ukrayna', 'savaÅŸÄ±nÄ±n', 'devam', 'etmesi', ',', 'petrol', 'fiyatlarÄ±nÄ±n', 'artmasÄ±yla', 'meydana', 'gelen', 'enerji', 'krizi', ',', 'gÄ±da', 'gÃ¼vensizliÄŸi', ',', 'ekonomik', 'kriz', 've', 'iklim', 'deÄŸiÅŸikliÄŸi', 'gibiâ€¦', 'http', ':', '//t.co/rrnocexgi', '@', 'huseyinkanturk', 'gÄ±da', 've', 'ilaÃ§', 'stoklamak', 'mÄ±', 'yoksa', 'bunlarÄ±n', 'hisselerini', 'almak', 'mÄ±', 'daha', 'yararlÄ±', 'olur', 'ğŸ˜‚ğŸ˜‚', 'bird', 'iklim', 'krizi', 'de', 'olacakmÄ±ÅŸ', '.', 'sanat']\n"
     ]
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "koklendirme = [ps.stem(kok) for kok in kelimeler]\n",
    "print(\"kok sonrasi : \",kelimeler[:200])\n",
    "print(\"-\"*100)\n",
    "print(\"kok sonrasi : \",koklendirme[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "61ab397f-c7ca-4ef8-b495-8aef735ceb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatize EdilmiÅŸ Kelimeler: @ Fapej_in_Tufegi YAAAAAAAAAAAAAAAAAAAAAA Neyse komÃ¼nist olmak da gÃ¼zel ÅŸey eÅŸitlik falan savunuyorsun iklim krizi olmuyor @ wolfintoaction Kurak geÃ§en bir yÄ±l var ortada kuraklÄ±k iyice baÅŸ gÃ¶sterip gÄ±da ve iklim krizi olursa beton ve diÄŸer menkul yahut gayrimenkullerin yenilip iÃ§ilmediÄŸi iÃ§in gÄ±dadan daha fazla Ã¶nem teÅŸkil etmeyecek gÃ¼n gelir Ã§erez parasÄ± da olur makyajlÄ± beton evler 2021 ; DoÄŸanÄ±n bize verdiklerinin yanÄ±nda bizim onu nasÄ±l hunharca yok ettiÄŸimizi hatÄ±rlattÄ± .. AdÄ±na ister iklim krizi deyin , ister baÅŸka birÅŸey .. http : //t.co/2rtifFHMfY Erzurum â€™ un yeni yÄ±la karsÄ±z girecek olmasÄ±â€¦ korkunÃ§â€¦ kÃ¼resel Ä±sÄ±nmaâ€¦ yok olan mevsimlerâ€¦ iklim kriziâ€¦ her ÅŸeyin deÄŸiÅŸmesiâ€¦ normal hiÃ§bir ÅŸey kalmamasÄ±â€¦ [ Ankara'nÄ±n iklim gÃ¼ndemi-9 ] HDP : Ä°klim krizi yeni kazanÃ§ kapÄ±sÄ± olamaz - YeÅŸil Gazete http : //t.co/0NGWYjSFAr iklim krizi yÃ¼zÃ¼nden , yÄ±l baÅŸÄ± bu sene yaza denk gelmiÅŸ gibi # Noel 2023'te dÃ¼nyayÄ± Rusya-Ukrayna krizinin etkileri ve enerji krizi riski bekliyor : 2023'te dÃ¼nyayÄ± Rusya-Ukrayna savaÅŸÄ±nÄ±n devam etmesi , petrol fiyatlarÄ±nÄ±n artmasÄ±yla meydana gelen enerji krizi , gÄ±da gÃ¼vensizliÄŸi , ekonomik kriz ve iklim deÄŸiÅŸikliÄŸi gibiâ€¦ http : //t.co/rRnOcexgYS @ huseyinkanturk gÄ±da ve ilaÃ§ stoklamak mÄ± yoksa bunlarÄ±n hisselerini almak mÄ± daha yararlÄ± olur ğŸ˜‚ğŸ˜‚ birde iklim krizi de olacakmÄ±ÅŸ . Sanat\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "lema_kelimeler = [lemmatizer.lemmatize(kelime) for kelime in kelimeler]\n",
    "print(\"Lemmatize EdilmiÅŸ Kelimeler:\", \" \".join(lema_kelimeler[:200]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ee2d1f4e-554d-45c9-92c6-4887d64d1bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TemizlenmiÅŸ Metin:  Fapej_in_Tufegi YAAAAAAAAAAAAAAAAAAAAAA   Neyse komÃ¼nist olmak da gÃ¼zel ÅŸey eÅŸitlik falan savunuyorsun iklim krizi olmuyor  wolfintoaction Kurak geÃ§en bir yÄ±l var ortada kuraklÄ±k iyice baÅŸ gÃ¶sterip g\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ham metin : @Fapej_in_Tufegi YAAAAAAAAAAAAAAAAAAAAAA \n",
      "\n",
      "Neyse komÃ¼nist olmak da gÃ¼zel ÅŸey eÅŸitlik falan savunuyorsun iklim krizi olmuyor @wolfintoaction Kurak geÃ§en bir yÄ±l var ortada kuraklÄ±k iyice baÅŸ gÃ¶sterip g\n"
     ]
    }
   ],
   "source": [
    "temiz_metin = re.sub(r'http\\S+|www\\S+|https\\S+', '', metin_list, flags=re.MULTILINE)\n",
    "temiz_metin = re.sub(r'\\W', ' ', temiz_metin)\n",
    "print(f\"TemizlenmiÅŸ Metin:\", temiz_metin[:200])\n",
    "print(\"-\"*100)\n",
    "print(f\"Ham metin :\",metin_list[:200])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "93cc8813-758c-4dbb-82f8-e6f7cb6924eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FiltrelenmiÅŸ Kelimeler: Fapej_in_Tufegi YAAAAAAAAAAAAAAAAAAAAAA Neyse komÃ¼nist olmak gÃ¼zel eÅŸitlik falan savunuyorsun iklim krizi olmuyor wolfintoaction Kurak geÃ§en bir yÄ±l var ortada kuraklÄ±k iyice baÅŸ gÃ¶sterip gÄ±da iklim krizi olursa beton diÄŸer menkul yahut gayrimenkullerin yenilip iÃ§ilmediÄŸi gÄ±dadan fazla Ã¶nem teÅŸkil etmeyecek gÃ¼n gelir Ã§erez parasÄ± olur makyajlÄ± beton evler 2021 DoÄŸanÄ±n bize verdiklerinin yanÄ±nda bizim onu hunharca yok ettiÄŸimizi hatÄ±rlattÄ± AdÄ±na ister iklim krizi deyin ister baÅŸka Erzurum un yeni yÄ±la karsÄ±z girecek olmasÄ± korkunÃ§ kÃ¼resel Ä±sÄ±nma yok olan mevsimler iklim krizi ÅŸeyin deÄŸiÅŸmesi normal hiÃ§bir kalmamasÄ± Ankara nÄ±n iklim gÃ¼ndemi 9 HDP Ä°klim krizi yeni kazanÃ§ kapÄ±sÄ± olamaz YeÅŸil Gazete iklim krizi yÃ¼zÃ¼nden yÄ±l baÅŸÄ± sene yaza denk gelmiÅŸ Noel 2023 te dÃ¼nyayÄ± Rusya Ukrayna krizinin etkileri enerji krizi riski bekliyor 2023 te dÃ¼nyayÄ± Rusya Ukrayna savaÅŸÄ±nÄ±n devam etmesi petrol fiyatlarÄ±nÄ±n artmasÄ±yla meydana gelen enerji krizi gÄ±da gÃ¼vensizliÄŸi ekonomik kriz iklim deÄŸiÅŸikliÄŸi huseyinkanturk gÄ±da ilaÃ§ stoklamak yoksa bunlarÄ±n hisselerini almak yararlÄ± olur birde iklim krizi olacakmÄ±ÅŸ Sanat spor iklim krizi ileri dÃ¶nÃ¼ÅŸÃ¼m odaÄŸÄ±mÄ±zda farkÄ±ndalÄ±ÄŸÄ±mÄ±zÄ±n arttÄ±ÄŸÄ± gidecek yolumuz gÃ¶recek yÄ±llarÄ±mÄ±z var dediÄŸimiz yaÅŸama karÅŸÄ± heyecanÄ±mÄ±zÄ±n kaybolmadÄ±ÄŸÄ± saÄŸlÄ±klÄ± mutlu huzurlu baÅŸarÄ±lÄ± umut dolu hoÅŸ gel 2 0 2 3 HappyNewYear HappyNewYear2023 Ankara nÄ±n iklim gÃ¼ndemi 9 HDP Ä°klim krizi yeni kazanÃ§ kapÄ±sÄ± olamaz\n",
      "YakalanmÄ±ÅŸ Stopwords  : da ÅŸey ve ve iÃ§in daha da nasÄ±l birÅŸey her ÅŸey bu gibi ve ve gibi ve mÄ± mÄ± daha de daha Ã§ok ile ve ve gibi biri ve ve bu ne diye ne ile Ve ve hep ve bu Ã§ok ile ve da ve ve gibi ve ya daha Ã§ok ve ve de iÃ§in neden ile en ne diye ne da yani Bu Bu Bu Bu Bu Her ÅŸey Ã§ok tÃ¼m bu bu ve her gibi iÃ§in bu ve ve daha bu daha Ã§ok da ve gibi ve bazÄ± Sanki kez bu bu ki da ve mu bu Ã‡ok de ya ya ki az da bu iÃ§in en ve veya Ã§ok daha ile daha ama ve biz iÃ§in Bu birkaÃ§ da ÅŸey bu AslÄ±nda iÃ§in bu bu da de daha ile iÃ§in ya gibi da Bu mÄ± mÄ± yani En Ã§ok ve en ise ve iÃ§in da da diye siz de daha ve ama ve tÃ¼m ile ve en tÃ¼m en her biri en az ya da Ama defa bu da ki Ã§ok ve diye hepsi de ne defa ya yani mÄ± en Ã§ok ya bu tÃ¼m ve bu iÃ§in ne ÅŸu gibi ve iÃ§in ve iÃ§in ve ve\n"
     ]
    }
   ],
   "source": [
    "stop_kelimeler = set(stopwords.words('turkish'))\n",
    "\n",
    "filtrelenmis_kelimeler = [kelime for kelime in nltk.word_tokenize(temiz_metin) if kelime.lower() not in stop_kelimeler]\n",
    "stop_words = [kelime for kelime in nltk.word_tokenize(temiz_metin) if kelime.lower() in stop_kelimeler]\n",
    "print(\"FiltrelenmiÅŸ Kelimeler:\", \" \".join(filtrelenmis_kelimeler[:200]))\n",
    "print(\"YakalanmÄ±ÅŸ Stopwords  :\", \" \".join(stop_words[:200]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "438efe20-1c74-4c61-953e-7f6ad61ca3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "kucuk_harfli_metin = metin_list.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "02732f9c-083f-4560-91d9-2e819ebb9de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizasyon_metin = re.sub(r'[^\\w\\s]', '', kucuk_harfli_metin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8e2f4848-500e-4297-b7cf-89b371c90b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(series, remove_hashtag=False, remove_mentions=False, remove_links=False, remove_numbers=False,\n",
    "                  remove_short_text=False, lowercase=False, remove_punctuation=False, remove_stopwords=False,\n",
    "                  remove_rare_words=False, rare_limit=5):    \n",
    "    if lowercase:\n",
    "        print(\"KÃ¼Ã§Ã¼k harfe Ã§eviriliyor...\")\n",
    "        start = timer()\n",
    "        series = series.str.lower()\n",
    "        print(f\"KÃ¼Ã§Ã¼k harfe Ã§evirme iÅŸlemi {timedelta(seconds=timer() - start)} iÃ§inde tamamlandÄ±.\")\n",
    "\n",
    "    if remove_hashtag:\n",
    "        print(\"Hashtagler kaldÄ±rÄ±lÄ±yor...\")\n",
    "        start = timer()\n",
    "        series = series.str.replace(r'((#)[^\\s]*)\\b', '', regex=True)\n",
    "        print(f\"KaldÄ±rma iÅŸlemi {timedelta(seconds=timer() - start)} iÃ§inde tamamlandÄ±.\")\n",
    "\n",
    "    if remove_mentions:\n",
    "        print(\"Mentionlar kaldÄ±rÄ±lÄ±yor...\")\n",
    "        start = timer()\n",
    "        series = series.str.replace(r'((@)[^\\s]*)\\b', '', regex=True)\n",
    "        print(f\"KaldÄ±rma iÅŸlemi {timedelta(seconds=timer() - start)} iÃ§inde tamamlandÄ±.\")\n",
    "\n",
    "    if remove_links:\n",
    "        print(\"Linkler kaldÄ±rÄ±lÄ±yor...\")\n",
    "        start = timer()\n",
    "        series = series.str.replace(r'\\n', '', regex=True)\n",
    "        series = series.apply(lambda x: re.split('https:\\/\\/.*', str(x))[0])\n",
    "        print(f\"KaldÄ±rma iÅŸlemi {timedelta(seconds=timer() - start)} iÃ§inde tamamlandÄ±.\")\n",
    "\n",
    "    if remove_numbers:\n",
    "        print(\"SayÄ±lar kaldÄ±rÄ±lÄ±yor...\")\n",
    "        start = timer()\n",
    "        series = series.str.replace(r'\\d+', '', regex=True)\n",
    "        print(f\"KaldÄ±rma iÅŸlemi {timedelta(seconds=timer() - start)} iÃ§inde tamamlandÄ±.\")\n",
    "\n",
    "    if remove_short_text:\n",
    "        print(\"KÄ±sa metinler kaldÄ±rÄ±lÄ±yor...\")\n",
    "        start = timer()\n",
    "        series = series.apply(lambda x: re.sub(r'\\b\\w{1,2}\\b', '', x))\n",
    "        print(f\"KaldÄ±rma iÅŸlemi {timedelta(seconds=timer() - start)} iÃ§inde tamamlandÄ±.\")\n",
    "\n",
    "    if remove_punctuation:\n",
    "        print(\"Noktalama iÅŸaretleri kaldÄ±rÄ±lÄ±yor...\")\n",
    "        start = timer()\n",
    "        series = series.str.replace(r\"((')[^\\s]*)\\b\", '', regex=True)\n",
    "        series = series.str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "        print(f\"KaldÄ±rma iÅŸlemi {timedelta(seconds=timer() - start)} iÃ§inde tamamlandÄ±.\")\n",
    "\n",
    "    if remove_stopwords:\n",
    "        print(\"Removing stopwords...\")\n",
    "        start = timer()\n",
    "        # Stopwordsleri veri setinden kaldÄ±rma iÅŸlemi\n",
    "        series = series.apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in stop_kelimeler]))\n",
    "        print(f\"Stopwords are removed in {timedelta(seconds=timer() - start)}\")\n",
    "\n",
    "    if remove_rare_words:\n",
    "        print(\"Nadir kelimeler kaldÄ±rÄ±lÄ±yor...\")\n",
    "        start = timer()\n",
    "        whole_count = pd.Series(\" \".join(series).split()).value_counts()\n",
    "        print(f\"Seride toplam {whole_count.count()} kelime var.\")\n",
    "        print(f\"%{round(whole_count[whole_count <= rare_limit].count() / whole_count.count() * 100, 2)} oranÄ±nda kelime, nadir limitinden ({rare_limit}) daha az kez gÃ¶rÃ¼nÃ¼yor.\")\n",
    "        to_remove = whole_count[whole_count <= rare_limit]\n",
    "        print(\"Nadir kelimeler kaldÄ±rÄ±lÄ±yor...\")\n",
    "        series = series.apply(lambda x: \" \".join(x for x in x.split() if x not in to_remove))\n",
    "        print(f\"{len(to_remove)} nadir kelime kaldÄ±rÄ±ldÄ±.\")\n",
    "        print(f\"KaldÄ±rma iÅŸlemi {timedelta(seconds=timer() - start)} iÃ§inde tamamlandÄ±.\")\n",
    "\n",
    "    return series\n",
    "\n",
    "\n",
    "def tr_en_char_translate(series):\n",
    "    \"\"\"\n",
    "    Tasks\n",
    "    -----\n",
    "        Convert Turkish characters to English characters.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    series: pandas.Series\n",
    "        The series to be translated.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    series: pandas.Series\n",
    "        The translated series.\n",
    "    \"\"\"\n",
    "    series = series.str.replace('Ä±', 'i')\n",
    "    series = series.str.replace('Ã¼', 'u')\n",
    "    series = series.str.replace('Ã¶', 'o')\n",
    "    series = series.str.replace('ÄŸ', 'g')\n",
    "    series = series.str.replace('ÅŸ', 's')\n",
    "    series = series.str.replace('Ã§', 'c')\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "11620a03-3ea7-40ac-83ea-98ba5b161d43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KÃ¼Ã§Ã¼k harfe Ã§eviriliyor...\n",
      "KÃ¼Ã§Ã¼k harfe Ã§evirme iÅŸlemi 0:00:00.056382 iÃ§inde tamamlandÄ±.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>icerik</th>\n",
       "      <th>icerik_lowercased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Fapej_in_Tufegi YAAAAAAAAAAAAAAAAAAAAAA \\n\\nN...</td>\n",
       "      <td>@fapej_in_tufegi yaaaaaaaaaaaaaaaaaaaaaa \\n\\nn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@wolfintoaction Kurak geÃ§en bir yÄ±l var ortada...</td>\n",
       "      <td>@wolfintoaction kurak geÃ§en bir yÄ±l var ortada...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021 ; DoÄŸanÄ±n bize verdiklerinin yanÄ±nda bizi...</td>\n",
       "      <td>2021 ; doÄŸanÄ±n bize verdiklerinin yanÄ±nda bizi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Erzurumâ€™un yeni yÄ±la karsÄ±z girecek olmasÄ±â€¦ ko...</td>\n",
       "      <td>erzurumâ€™un yeni yÄ±la karsÄ±z girecek olmasÄ±â€¦ ko...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Ankara'nÄ±n iklim gÃ¼ndemi-9] HDP: Ä°klim krizi ...</td>\n",
       "      <td>[ankara'nÄ±n iklim gÃ¼ndemi-9] hdp: iÌ‡klim krizi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>iklim krizi yÃ¼zÃ¼nden, yÄ±l baÅŸÄ± bu sene yaza de...</td>\n",
       "      <td>iklim krizi yÃ¼zÃ¼nden, yÄ±l baÅŸÄ± bu sene yaza de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023'te dÃ¼nyayÄ± Rusya-Ukrayna krizinin etkiler...</td>\n",
       "      <td>2023'te dÃ¼nyayÄ± rusya-ukrayna krizinin etkiler...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@huseyinkanturk gÄ±da ve ilaÃ§ stoklamak mÄ± yoks...</td>\n",
       "      <td>@huseyinkanturk gÄ±da ve ilaÃ§ stoklamak mÄ± yoks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sanat,spor,iklim krizi,ileri dÃ¶nÃ¼ÅŸÃ¼m odaÄŸÄ±mÄ±zd...</td>\n",
       "      <td>sanat,spor,iklim krizi,ileri dÃ¶nÃ¼ÅŸÃ¼m odaÄŸÄ±mÄ±zd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[Ankara'nÄ±n iklim gÃ¼ndemi-9] HDP: Ä°klim krizi ...</td>\n",
       "      <td>[ankara'nÄ±n iklim gÃ¼ndemi-9] hdp: iÌ‡klim krizi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[Ankara'nÄ±n iklim gÃ¼ndemi-9] HDP: Ä°klim krizi ...</td>\n",
       "      <td>[ankara'nÄ±n iklim gÃ¼ndemi-9] hdp: iÌ‡klim krizi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023'te dÃ¼nyayÄ± Rusya-Ukrayna krizinin etkiler...</td>\n",
       "      <td>2023'te dÃ¼nyayÄ± rusya-ukrayna krizinin etkiler...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2022 yÄ±lÄ±nda sanat dÃ¼nyasÄ±na damga vuran olayl...</td>\n",
       "      <td>2022 yÄ±lÄ±nda sanat dÃ¼nyasÄ±na damga vuran olayl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Peki enerji krizi kÄ±tasal baÄŸÄ±mlÄ±lÄ±klar yaratÄ±...</td>\n",
       "      <td>peki enerji krizi kÄ±tasal baÄŸÄ±mlÄ±lÄ±klar yaratÄ±...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Cemalettin TaÅŸcÄ± ile Ve Fakat'Ä±n yeni bÃ¶lÃ¼mÃ¼nd...</td>\n",
       "      <td>cemalettin taÅŸcÄ± ile ve fakat'Ä±n yeni bÃ¶lÃ¼mÃ¼nd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2023'te \"hep birlikte\" Ã¶zgÃ¼rce ve mutlulukla y...</td>\n",
       "      <td>2023'te \"hep birlikte\" Ã¶zgÃ¼rce ve mutlulukla y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>KÄ±ÅŸÄ±n ortasÄ±ndaki bu kuraklÄ±k Ã§ok can sÄ±kÄ±cÄ±, ...</td>\n",
       "      <td>kÄ±ÅŸÄ±n ortasÄ±ndaki bu kuraklÄ±k Ã§ok can sÄ±kÄ±cÄ±, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>â€˜DÄ°RENÃ‡LÄ° Ä°ÅLETMELERâ€™ PROJESÄ°NDE EÄÄ°TÄ°MLER TAM...</td>\n",
       "      <td>â€˜diÌ‡renÃ§liÌ‡ iÌ‡ÅŸletmelerâ€™ projesiÌ‡nde eÄŸiÌ‡tiÌ‡ml...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Rusya-Ukrayna savaÅŸÄ±nÄ±n da etkileriyle bÃ¶lgese...</td>\n",
       "      <td>rusya-ukrayna savaÅŸÄ±nÄ±n da etkileriyle bÃ¶lgese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>KÃ¼resel Ä±sÄ±nma, iklim krizi, saldÄ±rÄ±lar, herke...</td>\n",
       "      <td>kÃ¼resel Ä±sÄ±nma, iklim krizi, saldÄ±rÄ±lar, herke...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               icerik  \\\n",
       "0   @Fapej_in_Tufegi YAAAAAAAAAAAAAAAAAAAAAA \\n\\nN...   \n",
       "1   @wolfintoaction Kurak geÃ§en bir yÄ±l var ortada...   \n",
       "2   2021 ; DoÄŸanÄ±n bize verdiklerinin yanÄ±nda bizi...   \n",
       "3   Erzurumâ€™un yeni yÄ±la karsÄ±z girecek olmasÄ±â€¦ ko...   \n",
       "4   [Ankara'nÄ±n iklim gÃ¼ndemi-9] HDP: Ä°klim krizi ...   \n",
       "5   iklim krizi yÃ¼zÃ¼nden, yÄ±l baÅŸÄ± bu sene yaza de...   \n",
       "6   2023'te dÃ¼nyayÄ± Rusya-Ukrayna krizinin etkiler...   \n",
       "7   @huseyinkanturk gÄ±da ve ilaÃ§ stoklamak mÄ± yoks...   \n",
       "8   Sanat,spor,iklim krizi,ileri dÃ¶nÃ¼ÅŸÃ¼m odaÄŸÄ±mÄ±zd...   \n",
       "9   [Ankara'nÄ±n iklim gÃ¼ndemi-9] HDP: Ä°klim krizi ...   \n",
       "10  [Ankara'nÄ±n iklim gÃ¼ndemi-9] HDP: Ä°klim krizi ...   \n",
       "11  2023'te dÃ¼nyayÄ± Rusya-Ukrayna krizinin etkiler...   \n",
       "12  2022 yÄ±lÄ±nda sanat dÃ¼nyasÄ±na damga vuran olayl...   \n",
       "13  Peki enerji krizi kÄ±tasal baÄŸÄ±mlÄ±lÄ±klar yaratÄ±...   \n",
       "14  Cemalettin TaÅŸcÄ± ile Ve Fakat'Ä±n yeni bÃ¶lÃ¼mÃ¼nd...   \n",
       "15  2023'te \"hep birlikte\" Ã¶zgÃ¼rce ve mutlulukla y...   \n",
       "16  KÄ±ÅŸÄ±n ortasÄ±ndaki bu kuraklÄ±k Ã§ok can sÄ±kÄ±cÄ±, ...   \n",
       "17  â€˜DÄ°RENÃ‡LÄ° Ä°ÅLETMELERâ€™ PROJESÄ°NDE EÄÄ°TÄ°MLER TAM...   \n",
       "18  Rusya-Ukrayna savaÅŸÄ±nÄ±n da etkileriyle bÃ¶lgese...   \n",
       "19  KÃ¼resel Ä±sÄ±nma, iklim krizi, saldÄ±rÄ±lar, herke...   \n",
       "\n",
       "                                    icerik_lowercased  \n",
       "0   @fapej_in_tufegi yaaaaaaaaaaaaaaaaaaaaaa \\n\\nn...  \n",
       "1   @wolfintoaction kurak geÃ§en bir yÄ±l var ortada...  \n",
       "2   2021 ; doÄŸanÄ±n bize verdiklerinin yanÄ±nda bizi...  \n",
       "3   erzurumâ€™un yeni yÄ±la karsÄ±z girecek olmasÄ±â€¦ ko...  \n",
       "4   [ankara'nÄ±n iklim gÃ¼ndemi-9] hdp: iÌ‡klim krizi...  \n",
       "5   iklim krizi yÃ¼zÃ¼nden, yÄ±l baÅŸÄ± bu sene yaza de...  \n",
       "6   2023'te dÃ¼nyayÄ± rusya-ukrayna krizinin etkiler...  \n",
       "7   @huseyinkanturk gÄ±da ve ilaÃ§ stoklamak mÄ± yoks...  \n",
       "8   sanat,spor,iklim krizi,ileri dÃ¶nÃ¼ÅŸÃ¼m odaÄŸÄ±mÄ±zd...  \n",
       "9   [ankara'nÄ±n iklim gÃ¼ndemi-9] hdp: iÌ‡klim krizi...  \n",
       "10  [ankara'nÄ±n iklim gÃ¼ndemi-9] hdp: iÌ‡klim krizi...  \n",
       "11  2023'te dÃ¼nyayÄ± rusya-ukrayna krizinin etkiler...  \n",
       "12  2022 yÄ±lÄ±nda sanat dÃ¼nyasÄ±na damga vuran olayl...  \n",
       "13  peki enerji krizi kÄ±tasal baÄŸÄ±mlÄ±lÄ±klar yaratÄ±...  \n",
       "14  cemalettin taÅŸcÄ± ile ve fakat'Ä±n yeni bÃ¶lÃ¼mÃ¼nd...  \n",
       "15  2023'te \"hep birlikte\" Ã¶zgÃ¼rce ve mutlulukla y...  \n",
       "16  kÄ±ÅŸÄ±n ortasÄ±ndaki bu kuraklÄ±k Ã§ok can sÄ±kÄ±cÄ±, ...  \n",
       "17  â€˜diÌ‡renÃ§liÌ‡ iÌ‡ÅŸletmelerâ€™ projesiÌ‡nde eÄŸiÌ‡tiÌ‡ml...  \n",
       "18  rusya-ukrayna savaÅŸÄ±nÄ±n da etkileriyle bÃ¶lgese...  \n",
       "19  kÃ¼resel Ä±sÄ±nma, iklim krizi, saldÄ±rÄ±lar, herke...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['icerik_lowercased'] = preprocessing(df['icerik'], lowercase=True)\n",
    "df[['icerik', 'icerik_lowercased']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dcb57b1f-124b-436a-b33e-2c7fb0fcb693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mentionlar kaldÄ±rÄ±lÄ±yor...\n",
      "KaldÄ±rma iÅŸlemi 0:00:00.030039 iÃ§inde tamamlandÄ±.\n",
      "Linkler kaldÄ±rÄ±lÄ±yor...\n",
      "KaldÄ±rma iÅŸlemi 0:00:00.053703 iÃ§inde tamamlandÄ±.\n",
      "SayÄ±lar kaldÄ±rÄ±lÄ±yor...\n",
      "KaldÄ±rma iÅŸlemi 0:00:00.091331 iÃ§inde tamamlandÄ±.\n",
      "KÄ±sa metinler kaldÄ±rÄ±lÄ±yor...\n",
      "KaldÄ±rma iÅŸlemi 0:00:00.165192 iÃ§inde tamamlandÄ±.\n",
      "Noktalama iÅŸaretleri kaldÄ±rÄ±lÄ±yor...\n",
      "KaldÄ±rma iÅŸlemi 0:00:00.114298 iÃ§inde tamamlandÄ±.\n",
      "Nadir kelimeler kaldÄ±rÄ±lÄ±yor...\n",
      "Seride toplam 93814 kelime var.\n",
      "%63.46 oranÄ±nda kelime, nadir limitinden (1) daha az kez gÃ¶rÃ¼nÃ¼yor.\n",
      "Nadir kelimeler kaldÄ±rÄ±lÄ±yor...\n",
      "59530 nadir kelime kaldÄ±rÄ±ldÄ±.\n",
      "KaldÄ±rma iÅŸlemi 0:00:01.366426 iÃ§inde tamamlandÄ±.\n",
      "Removing stopwords...\n",
      "Stopwords are removed in 0:00:00.130652\n"
     ]
    }
   ],
   "source": [
    "df['icerik_mentions'] = preprocessing(df['icerik_lowercased'], remove_mentions=True)\n",
    "df['icerik_links'] = preprocessing(df['icerik_mentions'], remove_links=True)\n",
    "df['icerik_numbers'] = preprocessing(df['icerik_links'], remove_numbers=True)\n",
    "df['icerik_short_text'] = preprocessing(df['icerik_numbers'], remove_short_text=True)\n",
    "df['icerik_punctuation'] = preprocessing(df['icerik_short_text'], remove_punctuation=True)\n",
    "df['icerik_rare_words'] = preprocessing(df['icerik_punctuation'], remove_rare_words=True, rare_limit=1)\n",
    "df['icerik_stopwords'] = preprocessing(df['icerik_rare_words'], remove_stopwords=True)\n",
    "df['icerik_tr_en_char'] = tr_en_char_translate(df['icerik_stopwords'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2cb59f65-6490-4191-94b9-fe021ad92f0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>icerik</th>\n",
       "      <th>icerik_tr_en_char</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Fapej_in_Tufegi YAAAAAAAAAAAAAAAAAAAAAA \\n\\nN...</td>\n",
       "      <td>neyse komunist olmak guzel esitlik falan iklim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@wolfintoaction Kurak geÃ§en bir yÄ±l var ortada...</td>\n",
       "      <td>kurak gecen bir yil var ortada kuraklik iyice ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021 ; DoÄŸanÄ±n bize verdiklerinin yanÄ±nda bizi...</td>\n",
       "      <td>doganin bize yaninda bizim onu hunharca yok ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Erzurumâ€™un yeni yÄ±la karsÄ±z girecek olmasÄ±â€¦ ko...</td>\n",
       "      <td>erzurum yeni yila karsiz girecek olmasi korkun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Ankara'nÄ±n iklim gÃ¼ndemi-9] HDP: Ä°klim krizi ...</td>\n",
       "      <td>ankara iklim gundemi hdp klim krizi yeni kazan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>iklim krizi yÃ¼zÃ¼nden, yÄ±l baÅŸÄ± bu sene yaza de...</td>\n",
       "      <td>iklim krizi yuzunden yil basi sene yaza denk g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023'te dÃ¼nyayÄ± Rusya-Ukrayna krizinin etkiler...</td>\n",
       "      <td>dunyayi rusyaukrayna krizinin etkileri enerji ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@huseyinkanturk gÄ±da ve ilaÃ§ stoklamak mÄ± yoks...</td>\n",
       "      <td>gida ilac stoklamak yoksa bunlarin almak yarar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sanat,spor,iklim krizi,ileri dÃ¶nÃ¼ÅŸÃ¼m odaÄŸÄ±mÄ±zd...</td>\n",
       "      <td>donusum arttigi gidecek yolumuz gorecek yillar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[Ankara'nÄ±n iklim gÃ¼ndemi-9] HDP: Ä°klim krizi ...</td>\n",
       "      <td>ankara iklim gundemi hdp klim krizi yeni kazan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[Ankara'nÄ±n iklim gÃ¼ndemi-9] HDP: Ä°klim krizi ...</td>\n",
       "      <td>ankara iklim gundemi hdp klim krizi yeni kazan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023'te dÃ¼nyayÄ± Rusya-Ukrayna krizinin etkiler...</td>\n",
       "      <td>dunyayi rusyaukrayna krizinin etkileri enerji ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2022 yÄ±lÄ±nda sanat dÃ¼nyasÄ±na damga vuran olayl...</td>\n",
       "      <td>yilinda sanat dunyasina damga vuran olaylardan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Peki enerji krizi kÄ±tasal baÄŸÄ±mlÄ±lÄ±klar yaratÄ±...</td>\n",
       "      <td>peki enerji krizi kitasal bagimliliklar yarati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Cemalettin TaÅŸcÄ± ile Ve Fakat'Ä±n yeni bÃ¶lÃ¼mÃ¼nd...</td>\n",
       "      <td>fakat yeni bolumunde iklim krizi iklim aktivis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2023'te \"hep birlikte\" Ã¶zgÃ¼rce ve mutlulukla y...</td>\n",
       "      <td>birlikte ozgurce yasamak dilegiyle veganuary v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>KÄ±ÅŸÄ±n ortasÄ±ndaki bu kuraklÄ±k Ã§ok can sÄ±kÄ±cÄ±, ...</td>\n",
       "      <td>kisin ortasindaki kuraklik can sikici iklim kr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>â€˜DÄ°RENÃ‡LÄ° Ä°ÅLETMELERâ€™ PROJESÄ°NDE EÄÄ°TÄ°MLER TAM...</td>\n",
       "      <td>sletmeler projesinde genc nsanlari dernegi ikl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Rusya-Ukrayna savaÅŸÄ±nÄ±n da etkileriyle bÃ¶lgese...</td>\n",
       "      <td>rusyaukrayna savasinin etkileriyle bolgesel ku...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>KÃ¼resel Ä±sÄ±nma, iklim krizi, saldÄ±rÄ±lar, herke...</td>\n",
       "      <td>kuresel isinma iklim krizi saldirilar herkesin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               icerik  \\\n",
       "0   @Fapej_in_Tufegi YAAAAAAAAAAAAAAAAAAAAAA \\n\\nN...   \n",
       "1   @wolfintoaction Kurak geÃ§en bir yÄ±l var ortada...   \n",
       "2   2021 ; DoÄŸanÄ±n bize verdiklerinin yanÄ±nda bizi...   \n",
       "3   Erzurumâ€™un yeni yÄ±la karsÄ±z girecek olmasÄ±â€¦ ko...   \n",
       "4   [Ankara'nÄ±n iklim gÃ¼ndemi-9] HDP: Ä°klim krizi ...   \n",
       "5   iklim krizi yÃ¼zÃ¼nden, yÄ±l baÅŸÄ± bu sene yaza de...   \n",
       "6   2023'te dÃ¼nyayÄ± Rusya-Ukrayna krizinin etkiler...   \n",
       "7   @huseyinkanturk gÄ±da ve ilaÃ§ stoklamak mÄ± yoks...   \n",
       "8   Sanat,spor,iklim krizi,ileri dÃ¶nÃ¼ÅŸÃ¼m odaÄŸÄ±mÄ±zd...   \n",
       "9   [Ankara'nÄ±n iklim gÃ¼ndemi-9] HDP: Ä°klim krizi ...   \n",
       "10  [Ankara'nÄ±n iklim gÃ¼ndemi-9] HDP: Ä°klim krizi ...   \n",
       "11  2023'te dÃ¼nyayÄ± Rusya-Ukrayna krizinin etkiler...   \n",
       "12  2022 yÄ±lÄ±nda sanat dÃ¼nyasÄ±na damga vuran olayl...   \n",
       "13  Peki enerji krizi kÄ±tasal baÄŸÄ±mlÄ±lÄ±klar yaratÄ±...   \n",
       "14  Cemalettin TaÅŸcÄ± ile Ve Fakat'Ä±n yeni bÃ¶lÃ¼mÃ¼nd...   \n",
       "15  2023'te \"hep birlikte\" Ã¶zgÃ¼rce ve mutlulukla y...   \n",
       "16  KÄ±ÅŸÄ±n ortasÄ±ndaki bu kuraklÄ±k Ã§ok can sÄ±kÄ±cÄ±, ...   \n",
       "17  â€˜DÄ°RENÃ‡LÄ° Ä°ÅLETMELERâ€™ PROJESÄ°NDE EÄÄ°TÄ°MLER TAM...   \n",
       "18  Rusya-Ukrayna savaÅŸÄ±nÄ±n da etkileriyle bÃ¶lgese...   \n",
       "19  KÃ¼resel Ä±sÄ±nma, iklim krizi, saldÄ±rÄ±lar, herke...   \n",
       "\n",
       "                                    icerik_tr_en_char  \n",
       "0   neyse komunist olmak guzel esitlik falan iklim...  \n",
       "1   kurak gecen bir yil var ortada kuraklik iyice ...  \n",
       "2   doganin bize yaninda bizim onu hunharca yok ha...  \n",
       "3   erzurum yeni yila karsiz girecek olmasi korkun...  \n",
       "4   ankara iklim gundemi hdp klim krizi yeni kazan...  \n",
       "5   iklim krizi yuzunden yil basi sene yaza denk g...  \n",
       "6   dunyayi rusyaukrayna krizinin etkileri enerji ...  \n",
       "7   gida ilac stoklamak yoksa bunlarin almak yarar...  \n",
       "8   donusum arttigi gidecek yolumuz gorecek yillar...  \n",
       "9   ankara iklim gundemi hdp klim krizi yeni kazan...  \n",
       "10  ankara iklim gundemi hdp klim krizi yeni kazan...  \n",
       "11  dunyayi rusyaukrayna krizinin etkileri enerji ...  \n",
       "12  yilinda sanat dunyasina damga vuran olaylardan...  \n",
       "13  peki enerji krizi kitasal bagimliliklar yarati...  \n",
       "14  fakat yeni bolumunde iklim krizi iklim aktivis...  \n",
       "15  birlikte ozgurce yasamak dilegiyle veganuary v...  \n",
       "16  kisin ortasindaki kuraklik can sikici iklim kr...  \n",
       "17  sletmeler projesinde genc nsanlari dernegi ikl...  \n",
       "18  rusyaukrayna savasinin etkileriyle bolgesel ku...  \n",
       "19  kuresel isinma iklim krizi saldirilar herkesin...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['icerik', 'icerik_tr_en_char']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "07e6642a-2b3c-4e29-a5a6-22349152ab82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SÃ¼tunlardaki metinler birleÅŸtiriliyor.\n",
      "Toplam kelime sayÄ±larÄ± hesaplanÄ±yor.\n",
      "FarklÄ± kelime sayÄ±larÄ± hesaplanÄ±yor.\n",
      "En Ã§ok tekrar eden 10 kelime hesaplanÄ±yor.\n",
      "En az tekrar eden 10 kelime hesaplanÄ±yor.\n",
      "SÃ¼tun 1: icerik\n",
      "Toplam kelime sayÄ±sÄ±: 747547\n",
      "FarklÄ± kelime sayÄ±sÄ±: 161544\n",
      "En Ã§ok tekrar eden 10 kelime: [('iklim', 25495), ('krizi', 21082), ('ve', 15160), ('bir', 9972), ('bu', 5269), ('iÃ§in', 5057), ('#iklimkrizi', 5032), ('ile', 4429), ('de', 4066), ('da', 3734)]\n",
      "En az tekrar eden 10 kelime: [('alÄ±nmamasÄ±na', 1), ('gireyim', 1), ('tutardÄ±', 1), ('https://t.co/AgSr3bjsuO', 1), ('netliÄŸiyle', 1), ('ilkeler.', 1), ('gazetecisi', 1), ('https://t.co/ABdKzTjvog', 1), ('sÃ¼rdÃ¼rÃ¼lsÃ¼n.', 1), ('santralleriyle', 1)]\n",
      "\n",
      "\n",
      "SÃ¼tun 2: icerik_tr_en_char\n",
      "Toplam kelime sayÄ±sÄ±: 528373\n",
      "FarklÄ± kelime sayÄ±sÄ±: 32760\n",
      "En Ã§ok tekrar eden 10 kelime: [('iklim', 26677), ('krizi', 25839), ('bir', 10608), ('kuresel', 3722), ('klim', 3602), ('iklimkrizi', 3585), ('var', 2956), ('dunya', 2784), ('yok', 2496), ('degil', 2141)]\n",
      "En az tekrar eden 10 kelime: [('dinlemedik', 2), ('font', 2), ('duzeltilmesini', 2), ('yayinlayacagi', 2), ('yayinlayacakbiden', 2), ('devralmasinin', 2), ('grace', 2), ('dae', 2), ('deppoefes', 2), ('esmiyorsabirnedenivar', 2)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Metni temizle ve kelimelere ayÄ±r\n",
    "def preprocess_text(text):\n",
    "    words = text.split()  # Kelimelere ayÄ±r\n",
    "    return words\n",
    "\n",
    "\n",
    "def analyze_columns(df, column1, column2):\n",
    "    # SÃ¼tunlardaki metinleri birleÅŸtir ve kelimelere ayÄ±r\n",
    "    print(\"SÃ¼tunlardaki metinler birleÅŸtiriliyor.\")\n",
    "    words1 = df[column1].apply(preprocess_text).sum()\n",
    "    words2 = df[column2].apply(preprocess_text).sum()\n",
    "\n",
    "    # Toplam kelime sayÄ±larÄ±\n",
    "    print(\"Toplam kelime sayÄ±larÄ± hesaplanÄ±yor.\")\n",
    "    total_words1 = len(words1)\n",
    "    total_words2 = len(words2)\n",
    "\n",
    "    # FarklÄ± kelime sayÄ±larÄ±\n",
    "    print(\"FarklÄ± kelime sayÄ±larÄ± hesaplanÄ±yor.\")\n",
    "    unique_words1 = len(set(words1))\n",
    "    unique_words2 = len(set(words2))\n",
    "\n",
    "    # En Ã§ok tekrar eden 10 kelime\n",
    "    print(\"En Ã§ok tekrar eden 10 kelime hesaplanÄ±yor.\")\n",
    "    common_words1 = Counter(words1).most_common(10)\n",
    "    common_words2 = Counter(words2).most_common(10)\n",
    "\n",
    "    # En az tekrar eden 10 kelime\n",
    "    print(\"En az tekrar eden 10 kelime hesaplanÄ±yor.\")\n",
    "    least_common_words1 = Counter(words1).most_common()[:-11:-1]\n",
    "    least_common_words2 = Counter(words2).most_common()[:-11:-1]\n",
    "\n",
    "    # SonuÃ§larÄ± ekrana bas\n",
    "    print(f\"SÃ¼tun 1: {column1}\")\n",
    "    print(f\"Toplam kelime sayÄ±sÄ±: {total_words1}\")\n",
    "    print(f\"FarklÄ± kelime sayÄ±sÄ±: {unique_words1}\")\n",
    "    print(f\"En Ã§ok tekrar eden 10 kelime: {common_words1}\")\n",
    "    print(f\"En az tekrar eden 10 kelime: {least_common_words1}\")\n",
    "    print(\"\\n\")\n",
    "    print(f\"SÃ¼tun 2: {column2}\")\n",
    "    print(f\"Toplam kelime sayÄ±sÄ±: {total_words2}\")\n",
    "    print(f\"FarklÄ± kelime sayÄ±sÄ±: {unique_words2}\")\n",
    "    print(f\"En Ã§ok tekrar eden 10 kelime: {common_words2}\")\n",
    "    print(f\"En az tekrar eden 10 kelime: {least_common_words2}\")\n",
    "\n",
    "\n",
    "# DataFrame'deki sÃ¼tunlarÄ± analiz et\n",
    "analyze_columns(df, 'icerik', 'icerik_tr_en_char')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bfdaee-525f-4b33-8fc6-0d62a00596da",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6e2863-77dc-486a-b94a-6ab3cb379bc0",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d2f151-d97d-46cf-a11a-fb821430311c",
   "metadata": {},
   "source": [
    "-------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d548c0-5680-4ecc-9ffa-d33e27ab74b2",
   "metadata": {},
   "source": [
    "## Twitter verileri "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "991b4d8b-c10b-4679-96d0-0e4148c2b08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "veriler = pd.read_csv(\"twitter_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "fccd97cf-e0de-4890-9667-74d75221dc0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_ID</th>\n",
       "      <th>Username</th>\n",
       "      <th>Text</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>julie81</td>\n",
       "      <td>Party least receive say or single. Prevent pre...</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>2023-01-30 11:00:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>richardhester</td>\n",
       "      <td>Hotel still Congress may member staff. Media d...</td>\n",
       "      <td>35</td>\n",
       "      <td>29</td>\n",
       "      <td>2023-01-02 22:45:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>williamsjoseph</td>\n",
       "      <td>Nice be her debate industry that year. Film wh...</td>\n",
       "      <td>51</td>\n",
       "      <td>25</td>\n",
       "      <td>2023-01-18 11:25:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>danielsmary</td>\n",
       "      <td>Laugh explain situation career occur serious. ...</td>\n",
       "      <td>37</td>\n",
       "      <td>18</td>\n",
       "      <td>2023-04-10 22:06:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>carlwarren</td>\n",
       "      <td>Involve sense former often approach government...</td>\n",
       "      <td>27</td>\n",
       "      <td>80</td>\n",
       "      <td>2023-01-24 07:12:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tweet_ID        Username                                               Text  Retweets  Likes            Timestamp\n",
       "0         1         julie81  Party least receive say or single. Prevent pre...         2     25  2023-01-30 11:00:51\n",
       "1         2   richardhester  Hotel still Congress may member staff. Media d...        35     29  2023-01-02 22:45:58\n",
       "2         3  williamsjoseph  Nice be her debate industry that year. Film wh...        51     25  2023-01-18 11:25:19\n",
       "3         4     danielsmary  Laugh explain situation career occur serious. ...        37     18  2023-04-10 22:06:29\n",
       "4         5      carlwarren  Involve sense former often approach government...        27     80  2023-01-24 07:12:21"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "veriler.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "e9fbe1eb-e3e0-4aa9-a443-20eb46bbf772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet_ID     0\n",
       "Username     0\n",
       "Text         0\n",
       "Retweets     0\n",
       "Likes        0\n",
       "Timestamp    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "veriler.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "222fddfe-ebec-4120-bf8c-e0f4bb13ec7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metin_list = veriler[\"Text\"].to_list()\n",
    "metin_list_ham_veri = metin_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e65b477-124b-4b14-8d1f-232447d7979e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metin_list[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05af9509-b1c2-45d5-a0fa-cea2b6137a2b",
   "metadata": {},
   "source": [
    "    AdÄ±m adÄ±m Ã¶n iÅŸleme\n",
    "- Lowercase\n",
    "- Remove Punctuation\n",
    "- Handling Hashtags, Mentions, URLs\n",
    "- Remove Irrelevant Emojis\n",
    "- Frequency-based Word Removal\n",
    "- Remove Stopwords\n",
    "- Lexicon Normalization (Lemmatization or Stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f002767c-e4f5-448a-8d71-6b403a6a533b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## lowercase \n",
    "metin_list = [tweet.lower() for tweet in metin_list]\n",
    "## noktalama iÅŸaretleri\n",
    "metin_list = [''.join([char for char in tweet if char not in string.punctuation]) for tweet in metin_list]\n",
    "## stopwords kelimeleri \n",
    "stop_words = set(stopwords.words('english'))  # veya TÃ¼rkÃ§e iÃ§in 'turkish'\n",
    "metin_list = [' '.join([word for word in tweet.split() if word not in stop_words]) for tweet in metin_list]\n",
    "## mentions http olan iÃ§erikler\n",
    "metin_list = [re.sub(r'@\\w+|https?://\\S+|#', '', tweet) for tweet in metin_list]\n",
    "## emojiler\n",
    "metin_list = [re.sub(r'[^\\x00-\\x7F]+', '', tweet) for tweet in metin_list]\n",
    "\n",
    "print(\"*\"*100)\n",
    "print(\"Ham veri : \", metin_list_ham_veri[:10])\n",
    "print(\"*\"*100)\n",
    "print(\"Ä°ÅŸlenmiÅŸ veri : \",metin_list[:10])\n",
    "print(\"*\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "45fe067b-99f9-447e-ac1e-78f3bdada97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens :  ['party', 'least', 'receive', 'say', 'single', 'prevent', 'prevent', 'husband', 'affect', 'may']\n"
     ]
    }
   ],
   "source": [
    "## frekans\n",
    "kelimeler = nltk.word_tokenize(\"\".join(metin_list))\n",
    "print(\"Tokens : \",kelimeler[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b568bc-3e81-44d2-9137-9373da464f4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frekans = Counter(kelimeler)\n",
    "frekans\n",
    "\n",
    "## kelime sÄ±klÄ±klarÄ±"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e71141-76f1-42dc-b173-5d093fd65ec0",
   "metadata": {},
   "source": [
    "### Lemmatization veya Stemming iÅŸlemi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "ed1f6c0d-e57f-420d-a7ea-9f6a24429107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kelimelerin POS etiketlerini al\n",
    "pos_kelimeler = pos_tag(kelimeler)\n",
    "\n",
    "# Lemmatizer'Ä± oluÅŸtur\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Kelimeleri lemmatize et\n",
    "lemma_kelimeler = [\n",
    "    lemmatizer.lemmatize(kelime, pos=pos[0].lower()) if pos[0].lower() in ['a', 'r', 'n', 'v'] else lemmatizer.lemmatize(kelime)\n",
    "    for kelime, pos in pos_kelimeler\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "57f62406-81d4-449a-a41b-42dddf38fd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before :  ['party', 'least', 'receive', 'say', 'single', 'prevent', 'prevent', 'husband', 'affect', 'may', 'cup', 'style', 'evening', 'protect', 'effect', 'another', 'stage', 'perform', 'possible', 'try', 'tax', 'share', 'style', 'television', 'successful', 'much', 'sell', 'development', 'economy', 'effecthotel', 'still', 'congress', 'may', 'member', 'staff', 'media', 'draw', 'buy', 'fly', 'identify', 'another', 'turn', 'minute', 'would', 'local', 'subject', 'way', 'believe', 'question', 'message', 'imagine', 'join', 'agency', 'indicatenice', 'debate', 'industry', 'year', 'film', 'generation', 'push', 'discover', 'partner', 'level', 'nearly', 'money', 'store', 'style', 'may', 'enjoy', 'kid', 'discuss', 'blue', 'save', 'model', 'another', 'along', 'everybody', 'especially', 'dinner', 'character', 'yardlaugh', 'explain', 'situation', 'career', 'occur', 'serious', 'five', 'particular', 'important', 'size']\n",
      "****************************************************************************************************\n",
      "After :  ['party', 'least', 'receive', 'say', 'single', 'prevent', 'prevent', 'husband', 'affect', 'may', 'cup', 'style', 'even', 'protect', 'effect', 'another', 'stage', 'perform', 'possible', 'try', 'tax', 'share', 'style', 'television', 'successful', 'much', 'sell', 'development', 'economy', 'effecthotel', 'still', 'congress', 'may', 'member', 'staff', 'medium', 'draw', 'buy', 'fly', 'identify', 'another', 'turn', 'minute', 'would', 'local', 'subject', 'way', 'believe', 'question', 'message', 'imagine', 'join', 'agency', 'indicatenice', 'debate', 'industry', 'year', 'film', 'generation', 'push', 'discover', 'partner', 'level', 'nearly', 'money', 'store', 'style', 'may', 'enjoy', 'kid', 'discus', 'blue', 'save', 'model', 'another', 'along', 'everybody', 'especially', 'dinner', 'character', 'yardlaugh', 'explain', 'situation', 'career', 'occur', 'serious', 'five', 'particular', 'important', 'size']\n"
     ]
    }
   ],
   "source": [
    "print(\"Before : \", kelimeler[:90])\n",
    "print(\"*\" * 100)\n",
    "print(\"After : \", lemma_kelimeler[:90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "87c614a8-005c-48fd-91d6-d4a9e1181cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(metin_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "9c6e0069-95bc-48cf-8108-bc29aa0ddce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orijinal Kelime Matrisi (Var/Yok)\n",
      "   build  building  business  buy  call  camera  campaign  candidate  capital  car\n",
      "0      0         0         0    0     0       0         0          0        0    0\n",
      "1      0         0         0    1     0       0         0          0        0    0\n",
      "2      0         0         0    0     0       0         0          0        0    0\n",
      "3      0         0         0    0     0       0         0          1        0    0\n",
      "4      0         0         0    0     0       0         0          0        0    0\n",
      "5      0         0         0    0     0       0         0          0        0    0\n",
      "6      1         0         0    0     0       0         0          0        0    0\n",
      "7      0         0         0    0     0       0         0          0        0    0\n",
      "8      0         0         0    0     0       0         0          0        0    0\n",
      "9      0         0         0    0     0       0         0          0        0    0\n",
      "\n",
      "Lemmatization SonrasÄ± Kelime Matrisi (Var/Yok)\n",
      "   build  building  business  buy  call  camera  campaign  candidate  capital  car\n",
      "0      0         0         0    0     0       0         0          0        0    0\n",
      "1      0         0         0    1     0       0         0          0        0    0\n",
      "2      0         0         0    0     0       0         0          0        0    0\n",
      "3      0         0         0    0     0       0         0          1        0    0\n",
      "4      0         0         0    0     0       0         0          0        0    0\n",
      "5      0         0         0    0     0       0         0          0        0    0\n",
      "6      1         0         0    0     0       0         0          0        0    0\n",
      "7      0         0         0    0     0       0         0          0        0    0\n",
      "8      0         0         0    0     0       0         0          0        0    0\n",
      "9      0         0         0    0     0       0         0          0        0    0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ã‡Ä±ktÄ±yÄ± yan yana gÃ¶rebilmek adÄ±na\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.width', 250)\n",
    "# Kelimeleri sÃ¼tun isimleri olarak alÄ±yoruz\n",
    "df_original = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "print(\"Orijinal Kelime Matrisi (Var/Yok)\")\n",
    "print(df_original.iloc[:10,100:110])\n",
    "\n",
    "# Lemmatization iÅŸlemi iÃ§in WordNetLemmatizer kullanÄ±yoruz\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Her kelimenin tÃ¼rÃ¼nÃ¼ bulup lemmatize ediyoruz\n",
    "words_pos = pos_tag(vectorizer.get_feature_names_out())\n",
    "lemmatized_words = [lemmatizer.lemmatize(word, get_wordnet_pos(tag)) for word, tag in words_pos]\n",
    "\n",
    "# Lemmatized kelimelerle bir dict oluÅŸturup aynÄ± kelimeyi tekrar etmemesi iÃ§in set kullanÄ±yoruz\n",
    "lemmatized_word_dict = {word: lemmatizer.lemmatize(word, get_wordnet_pos(tag)) for word, tag in words_pos}\n",
    "df_lemmatized = df_original.rename(columns=lemmatized_word_dict)\n",
    "\n",
    "# AynÄ± kÃ¶ke sahip olan kelimeleri birleÅŸtiriyoruz\n",
    "df_lemmatized = df_lemmatized.groupby(axis=1, level=0, sort=False).sum()\n",
    "\n",
    "print(\"\\nLemmatization SonrasÄ± Kelime Matrisi (Var/Yok)\")\n",
    "print(df_lemmatized.iloc[:10,100:110])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "984eb75b-8389-43ba-8519-f94cf6d1e3ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_ID</th>\n",
       "      <th>Username</th>\n",
       "      <th>Text</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>islenmis_icerik</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>julie81</td>\n",
       "      <td>Party least receive say or single. Prevent pre...</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>2023-01-30 11:00:51</td>\n",
       "      <td>party least receive say single prevent prevent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>richardhester</td>\n",
       "      <td>Hotel still Congress may member staff. Media d...</td>\n",
       "      <td>35</td>\n",
       "      <td>29</td>\n",
       "      <td>2023-01-02 22:45:58</td>\n",
       "      <td>hotel still congress may member staff media dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>williamsjoseph</td>\n",
       "      <td>Nice be her debate industry that year. Film wh...</td>\n",
       "      <td>51</td>\n",
       "      <td>25</td>\n",
       "      <td>2023-01-18 11:25:19</td>\n",
       "      <td>nice debate industry year film generation push...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>danielsmary</td>\n",
       "      <td>Laugh explain situation career occur serious. ...</td>\n",
       "      <td>37</td>\n",
       "      <td>18</td>\n",
       "      <td>2023-04-10 22:06:29</td>\n",
       "      <td>laugh explain situation career occur serious f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>carlwarren</td>\n",
       "      <td>Involve sense former often approach government...</td>\n",
       "      <td>27</td>\n",
       "      <td>80</td>\n",
       "      <td>2023-01-24 07:12:21</td>\n",
       "      <td>involve sense former often approach government...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tweet_ID        Username                                               Text  Retweets  Likes            Timestamp                                    islenmis_icerik\n",
       "0         1         julie81  Party least receive say or single. Prevent pre...         2     25  2023-01-30 11:00:51  party least receive say single prevent prevent...\n",
       "1         2   richardhester  Hotel still Congress may member staff. Media d...        35     29  2023-01-02 22:45:58  hotel still congress may member staff media dr...\n",
       "2         3  williamsjoseph  Nice be her debate industry that year. Film wh...        51     25  2023-01-18 11:25:19  nice debate industry year film generation push...\n",
       "3         4     danielsmary  Laugh explain situation career occur serious. ...        37     18  2023-04-10 22:06:29  laugh explain situation career occur serious f...\n",
       "4         5      carlwarren  Involve sense former often approach government...        27     80  2023-01-24 07:12:21  involve sense former often approach government..."
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "veriler.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a36897-1b74-48c6-8f78-dd52b09e8856",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metin_list[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1805ad-63ed-4a84-bdf6-7b7ac8bafe86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(type(frekans))\n",
    "print(frekans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "2e6b2ade-5a61-46c4-9ebd-74cc6300eaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "least = frekans.values()\n",
    "least_key = frekans.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0154174-3239-437b-8252-2e17a40b9720",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(least)\n",
    "print(least_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "bd9d0076-d3d7-4294-99c2-b8f500d46332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En az tekrar eden kelimeler ve sÄ±klÄ±klarÄ± :  [('neverbody', 1), ('lineguess', 1), ('kindday', 1), ('seemborn', 1), ('manyagree', 1), ('becomeboy', 1), ('safemajor', 1), ('militarylisten', 1), ('troubledoctor', 1), ('viewrepresent', 1)]\n",
      "****************************************************************************************************\n",
      "En fazla tekrar eden kelimeler ve sÄ±klÄ±klarÄ± :  [('hard', 393), ('tax', 382), ('maybe', 377), ('job', 376), ('wear', 371), ('instead', 370), ('add', 370), ('piece', 369), ('check', 369), ('young', 369)]\n"
     ]
    }
   ],
   "source": [
    "def least_words(counter, n=10):\n",
    "    # En az tekrar eden n kelimeyi al\n",
    "    least = counter.most_common()[:-n-1:-1]  # En az tekrar eden n kelime\n",
    "    least_keys, least_values = zip(*least)  # Anahtar ve deÄŸerleri ayÄ±r\n",
    "    a = list(zip(least_keys, least_values))  # Anahtar ve deÄŸerleri birleÅŸtir ve listeye dÃ¶nÃ¼ÅŸtÃ¼r\n",
    "    # SonuÃ§larÄ± dÃ¶ndÃ¼r\n",
    "    return a\n",
    "\n",
    "def most_words(counter,n=10):\n",
    "    most = counter.most_common(10)\n",
    "    least_keys, least_values = zip(*most)  # Anahtar ve deÄŸerleri ayÄ±r\n",
    "    a = list(zip(least_keys, least_values))  # Anahtar ve deÄŸerleri birleÅŸtir ve listeye dÃ¶nÃ¼ÅŸtÃ¼r\n",
    "    return a\n",
    "\n",
    "\n",
    "print(\"En az tekrar eden kelimeler ve sÄ±klÄ±klarÄ± : \",least_words(frekans))\n",
    "print(\"*\"*100)\n",
    "print(\"En fazla tekrar eden kelimeler ve sÄ±klÄ±klarÄ± : \",most_words(frekans))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ab0b98-dbdc-4fb0-b1c8-313e19656ad8",
   "metadata": {},
   "source": [
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4097aab4-33cb-415c-85cc-a89110556dd3",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc2bed3-b55f-4a15-9eca-61cbbd416a84",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ea4cc2-c4f7-4c7c-a7ca-ec6a87cddfef",
   "metadata": {},
   "source": [
    "## Gender Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08c20d61-780c-4fb6-837c-66eee7a5c063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sbn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4602a1c0-aca6-42c6-ac60-9aed8f8e7c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>gender</th>\n",
       "      <th>gender:confidence</th>\n",
       "      <th>profile_yn</th>\n",
       "      <th>profile_yn:confidence</th>\n",
       "      <th>created</th>\n",
       "      <th>...</th>\n",
       "      <th>profileimage</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>sidebar_color</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_count</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>815719226</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/26/15 23:24</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12/5/13 1:48</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/414342229...</td>\n",
       "      <td>0</td>\n",
       "      <td>FFFFFF</td>\n",
       "      <td>Robbie E Responds To Critics After Win Against...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110964</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.587300e+17</td>\n",
       "      <td>main; @Kan1shk3</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>815719227</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/26/15 23:30</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10/1/12 13:51</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/539604221...</td>\n",
       "      <td>0</td>\n",
       "      <td>C0DEED</td>\n",
       "      <td>Â‰Ã›ÃIt felt like they were my friends and I was...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7471</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.587300e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>815719228</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/26/15 23:33</td>\n",
       "      <td>male</td>\n",
       "      <td>0.6625</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11/28/14 11:30</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/657330418...</td>\n",
       "      <td>1</td>\n",
       "      <td>C0DEED</td>\n",
       "      <td>i absolutely adore when louis starts the songs...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5617</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.587300e+17</td>\n",
       "      <td>clcncl</td>\n",
       "      <td>Belgrade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>815719229</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/26/15 23:10</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6/11/09 22:39</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/259703936...</td>\n",
       "      <td>0</td>\n",
       "      <td>C0DEED</td>\n",
       "      <td>Hi @JordanSpieth - Looking at the url - do you...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1693</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.587300e+17</td>\n",
       "      <td>Palo Alto, CA</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>815719230</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/27/15 1:15</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4/16/14 13:23</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/564094871...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Watching Neighbours on Sky+ catching up with t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31462</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.587300e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    _unit_id  _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
       "0  815719226    False   finalized                   3    10/26/15 23:24   \n",
       "1  815719227    False   finalized                   3    10/26/15 23:30   \n",
       "2  815719228    False   finalized                   3    10/26/15 23:33   \n",
       "3  815719229    False   finalized                   3    10/26/15 23:10   \n",
       "4  815719230    False   finalized                   3     10/27/15 1:15   \n",
       "\n",
       "   gender  gender:confidence profile_yn  profile_yn:confidence  \\\n",
       "0    male             1.0000        yes                    1.0   \n",
       "1    male             1.0000        yes                    1.0   \n",
       "2    male             0.6625        yes                    1.0   \n",
       "3    male             1.0000        yes                    1.0   \n",
       "4  female             1.0000        yes                    1.0   \n",
       "\n",
       "          created  ...                                       profileimage  \\\n",
       "0    12/5/13 1:48  ...  https://pbs.twimg.com/profile_images/414342229...   \n",
       "1   10/1/12 13:51  ...  https://pbs.twimg.com/profile_images/539604221...   \n",
       "2  11/28/14 11:30  ...  https://pbs.twimg.com/profile_images/657330418...   \n",
       "3   6/11/09 22:39  ...  https://pbs.twimg.com/profile_images/259703936...   \n",
       "4   4/16/14 13:23  ...  https://pbs.twimg.com/profile_images/564094871...   \n",
       "\n",
       "   retweet_count sidebar_color  \\\n",
       "0              0        FFFFFF   \n",
       "1              0        C0DEED   \n",
       "2              1        C0DEED   \n",
       "3              0        C0DEED   \n",
       "4              0             0   \n",
       "\n",
       "                                                text tweet_coord tweet_count  \\\n",
       "0  Robbie E Responds To Critics After Win Against...         NaN      110964   \n",
       "1  Â‰Ã›ÃIt felt like they were my friends and I was...         NaN        7471   \n",
       "2  i absolutely adore when louis starts the songs...         NaN        5617   \n",
       "3  Hi @JordanSpieth - Looking at the url - do you...         NaN        1693   \n",
       "4  Watching Neighbours on Sky+ catching up with t...         NaN       31462   \n",
       "\n",
       "    tweet_created      tweet_id   tweet_location               user_timezone  \n",
       "0  10/26/15 12:40  6.587300e+17  main; @Kan1shk3                     Chennai  \n",
       "1  10/26/15 12:40  6.587300e+17              NaN  Eastern Time (US & Canada)  \n",
       "2  10/26/15 12:40  6.587300e+17           clcncl                    Belgrade  \n",
       "3  10/26/15 12:40  6.587300e+17    Palo Alto, CA  Pacific Time (US & Canada)  \n",
       "4  10/26/15 12:40  6.587300e+17              NaN                         NaN  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"gender_classifier.csv\",encoding=\"latin1\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d198c6a-86af-4587-b097-0e5bdcf47426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20050, 26)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "7418aa0b-edd0-4b8c-98cc-551f7161d761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>i sing my own rhythm.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>I'm the author of novels filled with family dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>louis whining and squealing and all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>Mobile guy.  49ers, Shazam, Google, Kleiner Pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female</td>\n",
       "      <td>Ricky Wilson The Best FRONTMAN/Kaiser Chiefs T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>female</td>\n",
       "      <td>you don't know me.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>brand</td>\n",
       "      <td>A global marketplace for images, videos and mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>male</td>\n",
       "      <td>The secret of getting ahead is getting started.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>female</td>\n",
       "      <td>Pll Fan // Crazy about MCD // Ramen is bae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>female</td>\n",
       "      <td>Renaissance art historian, University of Notti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender                                        description\n",
       "0    male                              i sing my own rhythm.\n",
       "1    male  I'm the author of novels filled with family dr...\n",
       "2    male                louis whining and squealing and all\n",
       "3    male  Mobile guy.  49ers, Shazam, Google, Kleiner Pe...\n",
       "4  female  Ricky Wilson The Best FRONTMAN/Kaiser Chiefs T...\n",
       "5  female                                 you don't know me.\n",
       "6   brand  A global marketplace for images, videos and mu...\n",
       "7    male    The secret of getting ahead is getting started.\n",
       "8  female         Pll Fan // Crazy about MCD // Ramen is bae\n",
       "9  female  Renaissance art historian, University of Notti..."
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = pd.concat([data.gender,data.description],axis=1)\n",
    "data1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "87a06fd7-1b9d-420f-95de-f82aabbb4dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20050, 2)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ed83f9e0-579c-4014-8c14-52df85162cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16224, 2)\n"
     ]
    }
   ],
   "source": [
    "data1.dropna(inplace=True)\n",
    "data1.reset_index(drop=True,inplace=True)\n",
    "print(data1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "1ed47dd4-e74d-4fe3-a54e-551598fb4fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>i sing my own rhythm.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>I'm the author of novels filled with family dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>louis whining and squealing and all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Mobile guy.  49ers, Shazam, Google, Kleiner Pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Ricky Wilson The Best FRONTMAN/Kaiser Chiefs T...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender                                        description\n",
       "0       0                              i sing my own rhythm.\n",
       "1       0  I'm the author of novels filled with family dr...\n",
       "2       0                louis whining and squealing and all\n",
       "3       0  Mobile guy.  49ers, Shazam, Google, Kleiner Pe...\n",
       "4       1  Ricky Wilson The Best FRONTMAN/Kaiser Chiefs T..."
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.gender = [1 if i == \"female\" else 0 for i in data1.gender]\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "d09300f0-1357-4ecb-9293-18f418c16774",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "d2788f25-dddf-4a16-9eb5-274a85617fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "7b81ae1f-d4d7-402a-926b-c28dff754ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "liste = []\n",
    "\n",
    "for i in range(1000):\n",
    "    metin = re.sub(\"[^a-zA-Z]\",\" \",data1.description[i])\n",
    "    metin = metin.lower()\n",
    "    metin = metin.split()\n",
    "    metin = [lemma.lemmatize(j) for j in metin if not j in set(stopwords.words(\"english\"))]\n",
    "    metinson = \" \".join(metin)\n",
    "    liste.append(metinson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "506f0725-85c1-4f5d-a088-3e7571316c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features=10000)\n",
    "x = cv.fit_transform(liste).toarray()\n",
    "y = data1.iloc[:1000,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "9aa004d4-8058-4e21-9253-5807b9aa18c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sing rhythm',\n",
       " 'author novel filled family drama romance',\n",
       " 'louis whining squealing',\n",
       " 'mobile guy er shazam google kleiner perkins yahoo sprint pc airtouch air force stanford gsb uva dad husband brother golfer',\n",
       " 'ricky wilson best frontman kaiser chief best band xxxx thank kaiser chief incredible year gig memory cherish always xxxxxxx',\n",
       " 'know',\n",
       " 'global marketplace image video music sharing photo inspiration design tip video creative community',\n",
       " 'secret getting ahead getting started',\n",
       " 'pll fan crazy mcd ramen bae',\n",
       " 'renaissance art historian university nottingham fuelled haribo partial coffee soft spot renaissance china national teaching fellow']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liste[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d6bdf55f-64d8-4e23-8ca2-c259e8617e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "bdc5d436-1db9-4fd1-a4fe-b7c6f9669961",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "21a3cf65-2af0-4aa2-bee0-ccdea42660e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gn = GaussianNB()\n",
    "gn.fit(x_train,y_train)\n",
    "yhead = gn.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "9997d2e0-e5a7-4597-af8e-8c7e96b7381a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[96 46]\n",
      " [32 26]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test,yhead)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "8cff7b7e-b330-4498-bfae-1f5f61a2a60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.61\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(yhead, y_test))  # Compare predictions with true labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "ab9c3988-0104-47e5-95a1-9cf5052d7a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "5ee46697-2c85-473e-a4fb-7344d40daea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Accuracy score : 0.6933333333333334\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "XGBoost\n",
      "Accuracy score : 0.6733333333333333\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "K-Nearest Neighbors\n",
      "Accuracy score : 0.54\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Random Forest\n",
      "Accuracy score : 0.6933333333333334\n",
      "\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Random Forest': RandomForestClassifier()\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(model_name)\n",
    "    print(f\"Accuracy score : {accuracy_score(y_pred, y_test)}\")\n",
    "    print(\"\\n\" + \"-\"*40 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd1b342-2705-455b-a4e4-7bdbdf148100",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
